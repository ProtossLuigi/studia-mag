{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1520120a",
   "metadata": {},
   "source": [
    "### Laboratorium 9 - zadania\n",
    "\n",
    "Rozpakuj dołączone archiwum `dataset.zip` w folderze z notebookiem przed rozpoczęciem pracy.  \n",
    "Potrzebne Ci będą pakiety `scikit-learn` i `scikit-image` - doinstaluj, jeśli jeszcze nie posiadasz.\n",
    "\n",
    "Na tym laboratorium przetestujesz uproszczoną wersję detektora Violi-Jonesa dla obrazów twarzy. Uproszczenie polegało będzie na tym, że nie będziemy stosować pełnego pipeline'u kaskadowego, gdyż jego nauczenie jest dość skomplikowanym i długotrwałym procesem. Zastosowanie takiego gotowego detektora jest banalnie proste, dlatego internet roi się od lepszych i gorszych tutoriali. Dobre przykłady znajdziesz w dokumentacji [scikit-image](https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html) oraz [OpenCV](https://docs.opencv.org/4.5.4/db/d28/tutorial_cascade_classifier.html) - na obu stronach znajdziesz także pliki konfiguracyjne dla nauczonych detektorów.\n",
    "\n",
    "Funkcje (linki do dokumentacji), które należy mieć pod ręką na tym laboratorium:\n",
    "* [`skimage.transform.integral_image`](https://scikit-image.org/docs/dev/api/skimage.transform.html?highlight=integral_image#skimage.transform.integral_image)\n",
    "* [`skimage.feature.haar_like_feature`](https://scikit-image.org/docs/stable/api/skimage.feature.html#haar-like-feature) - oblicza (opcjonalnie: wybrane) cechy Haara dla podanego obrazu całkowego\n",
    "* [`skimage.feature.haar_like_feature_coord`](https://scikit-image.org/docs/stable/api/skimage.feature.html#haar-like-feature-coord) - wylicza koordynaty cech Haara\n",
    "* [`skimage.feature.draw_haar_like_feature`](https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.draw_haar_like_feature) - rysuje cechy Haara o podanych koordynatach\n",
    "* [`sklearn.ensemble.AdaBoostClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "\n",
    "Przykładów użycia nie zamieszczam w instrukcji bo są świetne w dokumentacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35a9b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import integral_image\n",
    "from skimage.feature import haar_like_feature, haar_like_feature_coord, draw_haar_like_feature\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02197a69",
   "metadata": {},
   "source": [
    "Poniższa komórka wczyta cały dataset w postaci pary (lista obrazów, lista etykiet). Obrazy skonwertuje od razu do skali szarości, ale skalowanie musisz wykonać własnoręcznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cebd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(path):\n",
    "    return list(cv2.imread(item.path, flags=cv2.IMREAD_GRAYSCALE) for item in os.scandir(path))\n",
    "\n",
    "positive_images = read_folder('natural_images_postprocessed/face')\n",
    "negative_images = read_folder('natural_images_postprocessed/noface')\n",
    "\n",
    "raw_images = positive_images + negative_images\n",
    "raw_targets = np.asarray(list(1 for _ in positive_images ) + list(0 for _ in negative_images), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b52c20",
   "metadata": {},
   "source": [
    "Poniższa komórka ładuje obrazy testowe do części badawczej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "772afbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = read_folder('test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ca331",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2474e7",
   "metadata": {},
   "source": [
    "#### Zadanie 1 (0.5 pkt | 0.0 pkt)\n",
    "\n",
    "Celem tego zadania jest nauczenie się korzystania z `haar_like_feature` i `haar_like_feature_coord`.\n",
    "\n",
    "##### Zadanie 1a\n",
    "\n",
    "Przetestuj pipeline do ekstrakcji cech Haara dla pojedynczego obrazu. Pamiętaj o skalowaniu! Sprawdź, ile cech otrzymujesz dla różnych skal pomiędzy 16x16 a 32x32. Zwróć uwagę, że `haar_like_feature` domyślnie ekstrahuje wszystkie możliwe cechy - być może wystarczą tylko niektóre z nich (np. tylko `type-2-x` i `type-2-y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1217a3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 14 18 ...  3  4  1]\n",
      "(269824,)\n"
     ]
    }
   ],
   "source": [
    "img = test_images[0]\n",
    "img = cv2.resize(img, (32, 32), interpolation = cv2.INTER_LINEAR)\n",
    "img = integral_image(img)\n",
    "\n",
    "features = haar_like_feature(img, 0, 0, 32, 32, feature_type=['type-2-x', 'type-2-y'])\n",
    "print(features)\n",
    "print(features.shape)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b8496",
   "metadata": {},
   "source": [
    "##### Zadanie 1b \n",
    "\n",
    "Użyj `haar_like_feature_coord` do wyznaczenia koordynat cech Haara dla podanej konfiguracji (rozmiar obrazka, wybrane typy cech). Wartości zwracane przez tę funkcję to para (coords, types) w nieco dziwnym typie:\n",
    "* coords to `np.array` o długości N=liczba cech, zawierający pythonowe listy dwuelementowe, zawierające punkty początkowy i końcowy prostokąta obejmującego daną cechę,\n",
    "* types to `np.array` o długości N=liczba cech, zawierający stringi identyfikujące typ danej cechy.\n",
    "\n",
    "Wybierz jedną dowolną cechę (na chybił trafił) i wyświetl ją używając `draw_haar_like_feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db58c938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type-2-x' 'type-2-x' 'type-2-x' ... 'type-2-y' 'type-2-y' 'type-2-y']\n",
      "[        -1         -1       -888 ... -743945644      10884  743956528]\n",
      "(269824,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13d38456460>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_raw = test_images[1]\n",
    "img_scaled = cv2.resize(img_raw, (32, 32), interpolation = cv2.INTER_LINEAR)\n",
    "img_int = integral_image(img_scaled)\n",
    "\n",
    "feature_coord, feature_type = haar_like_feature_coord(img_int.shape[0], img_int.shape[1], feature_type=['type-2-x', 'type-2-y'])\n",
    "features = haar_like_feature(img_int, 0, 0, 5, 5, feature_type=feature_type, feature_coord=feature_coord)\n",
    "print(features)\n",
    "print(features.shape)\n",
    "\n",
    "img_features = draw_haar_like_feature(img_scaled, 0, 0, 5, 5, feature_coord=feature_coord, max_n_features=1)\n",
    "plt.imshow(img_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ccc36b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zadanie 2 (0.75 pkt | 0.25 pkt)\n",
    "\n",
    "Dokonaj ekstrakcji cech Haara z całego datasetu. Dobierz parametry (skalowanie, typy cech) w taki sposób, by ekstrakcja nie trwała więcej niż 2-5 minut. Uformuj zbiory uczący i walidacyjny na potrzeby uczenia klasyfikatora, pamiętając o losowym samplowaniu z obu klas (np. używając [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)).\n",
    "Wykonaj uczenie klasyfikatora AdaBoost na tym zbiorze, zaczynając od niewielkiej liczby korzeni (N=10), powtarzając 2-3 razy dla większych wartości - ten proces również nie powinien trwać dłużej niż minutę. Na każdym etapie sprawdź, które cechy zostały wybrane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b757f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AdaBoostClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc234af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, size=(32,32), feature_type=['type-2-x', 'type-2-y']):\n",
    "    feature_coord, feature_type = haar_like_feature_coord(size[0], size[1], feature_type=feature_type)\n",
    "    features = []\n",
    "\n",
    "    for img in tqdm(images):\n",
    "        img = cv2.resize(img, size, interpolation = cv2.INTER_LINEAR)\n",
    "        img = integral_image(img)\n",
    "        haar_features = haar_like_feature(img, 0, 0, size[0], size[1], feature_type=feature_type, feature_coord=feature_coord)\n",
    "        features.append(haar_features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc781b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1976/1976 [01:17<00:00, 25.36it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_features = extract_features(raw_images, size=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f23a75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(extracted_features, raw_targets, train_size=0.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08b9fde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a911d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10d9a0",
   "metadata": {},
   "source": [
    "Poszczególne składniki klasyfikatora znajdują się w atrybucie `estimators_` (tworzonym dopiero po sfitowaniu). Aby dobrać się do konkretnych drzew (korzeni) decyzyjnych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98d1ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70399    -2    -2]\n",
      "[130.5  -2.   -2. ]\n",
      "|--- feature_70399 <= 130.50\n",
      "|   |--- class: 0\n",
      "|--- feature_70399 >  130.50\n",
      "|   |--- class: 1\n",
      "\n",
      "[22535    -2    -2]\n",
      "[76.5 -2.  -2. ]\n",
      "|--- feature_22535 <= 76.50\n",
      "|   |--- class: 0\n",
      "|--- feature_22535 >  76.50\n",
      "|   |--- class: 1\n",
      "\n",
      "[63781    -2    -2]\n",
      "[-18.5  -2.   -2. ]\n",
      "|--- feature_63781 <= -18.50\n",
      "|   |--- class: 1\n",
      "|--- feature_63781 >  -18.50\n",
      "|   |--- class: 0\n",
      "\n",
      "[71155    -2    -2]\n",
      "[ 3.5 -2.  -2. ]\n",
      "|--- feature_71155 <= 3.50\n",
      "|   |--- class: 0\n",
      "|--- feature_71155 >  3.50\n",
      "|   |--- class: 1\n",
      "\n",
      "[15013    -2    -2]\n",
      "[-87.5  -2.   -2. ]\n",
      "|--- feature_15013 <= -87.50\n",
      "|   |--- class: 1\n",
      "|--- feature_15013 >  -87.50\n",
      "|   |--- class: 0\n",
      "\n",
      "[1351   -2   -2]\n",
      "[254.5  -2.   -2. ]\n",
      "|--- feature_1351 <= 254.50\n",
      "|   |--- class: 0\n",
      "|--- feature_1351 >  254.50\n",
      "|   |--- class: 1\n",
      "\n",
      "[68296    -2    -2]\n",
      "[15.5 -2.  -2. ]\n",
      "|--- feature_68296 <= 15.50\n",
      "|   |--- class: 0\n",
      "|--- feature_68296 >  15.50\n",
      "|   |--- class: 1\n",
      "\n",
      "[69089    -2    -2]\n",
      "[62.5 -2.  -2. ]\n",
      "|--- feature_69089 <= 62.50\n",
      "|   |--- class: 0\n",
      "|--- feature_69089 >  62.50\n",
      "|   |--- class: 1\n",
      "\n",
      "[12297    -2    -2]\n",
      "[37.5 -2.  -2. ]\n",
      "|--- feature_12297 <= 37.50\n",
      "|   |--- class: 1\n",
      "|--- feature_12297 >  37.50\n",
      "|   |--- class: 0\n",
      "\n",
      "[68725    -2    -2]\n",
      "[777.5  -2.   -2. ]\n",
      "|--- feature_68725 <= 777.50\n",
      "|   |--- class: 1\n",
      "|--- feature_68725 >  777.50\n",
      "|   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tree_id in range(classifier.n_estimators):\n",
    "    my_tree = classifier.estimators_[tree_id].tree_ # konkretne drzewo (korzeń) -- NIE ZADZIAŁA PRZED NAUCZENIEM\n",
    "    print(my_tree.feature)   # cecha skojarzona z korzeniem; zwróć uwagę, że tylko pierwszy element zawiera id konkretnej cechy\n",
    "    print(my_tree.threshold) # próg decyzyjny dla tej cechy\n",
    "    print(sklearn.tree.export_text(classifier.estimators_[tree_id])) # pretty-printing powyższego, obiekt musi mieć atrybut 'tree_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f2bbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zadanie 3 (1.0 pkt | 0.25 pkt)\n",
    "\n",
    "Dla wybranego obrazu testowego wykonaj inferencję wykorzystując podejście *sliding-sindow*:\n",
    "* przeskaluj obraz źródłowy (możesz założyć a priori, że wiadomo jakiego rozmiaru będą twarze),\n",
    "* oblicz obraz całkowy,\n",
    "* dla każdego RoI wykonaj ekstrakcję cech Haara...\n",
    "* ...a następnie ich klasyfikację;\n",
    "* jeśli jest pozytywna - zapisz koordynaty danego RoI.\n",
    "\n",
    "Do prezentacji wyników możesz wykorzystać [`cv2.rectangle`](https://docs.opencv.org/4.5.4/d6/d6e/group__imgproc__draw.html#ga07d2f74cadcf8e305e810ce8eed13bc9) (przeskaluj wymiary znalezionego RoI w górę, by narysować bounding-boksa na obrazie oryginalnym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18cd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = test_images[5]\n",
    "test_img_int = integral_image(test_img)\n",
    "size = (24,24)\n",
    "feature_coord, feature_type = haar_like_feature_coord(size[0], size[1], feature_type=['type-2-x', 'type-2-y'])\n",
    "for y in range(test_img_int.shape[0] - size[0]):\n",
    "    for x in range(test_img_int.shape[1] - size[1]):\n",
    "        feature = haar_like_feature(test_img_int, x, y, size[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d2c08",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zadanie 4 (0.75 pkt | 0.0 pkt)\n",
    "\n",
    "Dokonaj optymalizacji algorytmu detekcji cech.\n",
    "\n",
    "##### Zadanie 4a (0.25 pkt)\n",
    "\n",
    "Ze znalezionych korzeni decyzyjnych łatwo wyciągniesz indeksy cech znaczących - wykorzystaj je oraz funkcję `haar_like_feature_coord` do znalezienia podzbioru koordynat cech Haara, które następnie przekażesz do funkcji `haar_like_feature` jako parę opcjonalnych parametrów `feature_type` i `feature_coord`. Sprawdź, o ile szybciej działa teraz ekstraktor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ded24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a97039e4",
   "metadata": {},
   "source": [
    "##### Zadanie 4b (0.5 pkt)\n",
    "\n",
    "Zmodyfikuj swój klasyfikator tak, aby korzystał ze zredukowanego zbioru cech. Proponowane rozwiązania:\n",
    "* (a) zmień parametr `features` w każdym z drzew, tak aby nie szukały cech w oryginalnym wektorze, a w zredukowanym,\n",
    "* (b) nie zmieniaj klasyfikatora, a zamiast tego mapuj zredukowane cechy do wektora o oryginalnej długości.\n",
    "\n",
    "Przetestuj cały pipeline na obrazach testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be84c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c08fa0fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zadanie 5 (0.0 pkt | 1.0 pkt)\n",
    "\n",
    "Wykonaj testy jakości detekcji dla klasyfikatorów o różnej liczbie cech. Wyniki omów, komentując mocne i słabe strony metody - ilościowe miary jakości nie są istotne (m.in. z tego powodu zbiór testowy jest tak niewielki i nie ma etykiet).\n",
    "\n",
    "Wykonaj testy wydajnościowe różnych klasyfikatorów. Dla porównania uwzględnij przynajmniej jeden przed optymalizacją ekstrakcji cech. Wyniki przedstaw w formie tabeli, mierząc średni czas przetwarzania jednego obrazu.\n",
    "\n",
    "#### Zadanie 6 (0.0 pkt | 0.5 pkt)\n",
    "\n",
    "Wykorzystaj dowolny znaleziony w internecie model głębokiej sieci neuronowej do detekcji twarzy, np. [https://github.com/timesler/facenet-pytorch](https://github.com/timesler/facenet-pytorch), porównując jego działanie z uzyskanymi w trakcie laboratorium klasyfikatorami pod względem jakości detekcji i szybkości działania."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
