{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1520120a",
   "metadata": {},
   "source": [
    "### Laboratorium 9 - zadania\n",
    "\n",
    "Rozpakuj dołączone archiwum `dataset.zip` w folderze z notebookiem przed rozpoczęciem pracy.  \n",
    "Potrzebne Ci będą pakiety `scikit-learn` i `scikit-image` - doinstaluj, jeśli jeszcze nie posiadasz.\n",
    "\n",
    "Na tym laboratorium przetestujesz uproszczoną wersję detektora Violi-Jonesa dla obrazów twarzy. Uproszczenie polegało będzie na tym, że nie będziemy stosować pełnego pipeline'u kaskadowego, gdyż jego nauczenie jest dość skomplikowanym i długotrwałym procesem. Zastosowanie takiego gotowego detektora jest banalnie proste, dlatego internet roi się od lepszych i gorszych tutoriali. Dobre przykłady znajdziesz w dokumentacji [scikit-image](https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html) oraz [OpenCV](https://docs.opencv.org/4.5.4/db/d28/tutorial_cascade_classifier.html) - na obu stronach znajdziesz także pliki konfiguracyjne dla nauczonych detektorów.\n",
    "\n",
    "Funkcje (linki do dokumentacji), które należy mieć pod ręką na tym laboratorium:\n",
    "* [`skimage.transform.integral_image`](https://scikit-image.org/docs/dev/api/skimage.transform.html?highlight=integral_image#skimage.transform.integral_image)\n",
    "* [`skimage.feature.haar_like_feature`](https://scikit-image.org/docs/stable/api/skimage.feature.html#haar-like-feature) - oblicza (opcjonalnie: wybrane) cechy Haara dla podanego obrazu całkowego\n",
    "* [`skimage.feature.haar_like_feature_coord`](https://scikit-image.org/docs/stable/api/skimage.feature.html#haar-like-feature-coord) - wylicza koordynaty cech Haara\n",
    "* [`skimage.feature.draw_haar_like_feature`](https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.draw_haar_like_feature) - rysuje cechy Haara o podanych koordynatach\n",
    "* [`sklearn.ensemble.AdaBoostClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "\n",
    "Przykładów użycia nie zamieszczam w instrukcji bo są świetne w dokumentacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a9b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import integral_image\n",
    "from skimage.feature import haar_like_feature\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sklearn.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02197a69",
   "metadata": {},
   "source": [
    "Poniższa komórka wczyta cały dataset w postaci pary (lista obrazów, lista etykiet). Obrazy skonwertuje od razu do skali szarości, ale skalowanie musisz wykonać własnoręcznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cebd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(path):\n",
    "    return list(cv2.imread(item.path, flags=cv2.IMREAD_GRAYSCALE) for item in os.scandir(path))\n",
    "\n",
    "positive_images = read_folder('natural_images_postprocessed/face')\n",
    "negative_images = read_folder('natural_images_postprocessed/noface')\n",
    "\n",
    "raw_images = positive_images + negative_images\n",
    "raw_targets = np.asarray(list(1 for _ in positive_images ) + list(0 for _ in negative_images), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b52c20",
   "metadata": {},
   "source": [
    "Poniższa komórka ładuje obrazy testowe do części badawczej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772afbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = read_folder('test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ca331",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2474e7",
   "metadata": {},
   "source": [
    "#### Zadanie 1 (0.5 pkt | 0.0 pkt)\n",
    "\n",
    "Celem tego zadania jest nauczenie się korzystania z `haar_like_feature` i `haar_like_feature_coord`.\n",
    "\n",
    "##### Zadanie 1a\n",
    "\n",
    "Przetestuj pipeline do ekstrakcji cech Haara dla pojedynczego obrazu. Pamiętaj o skalowaniu! Sprawdź, ile cech otrzymujesz dla różnych skal pomiędzy 16x16 a 32x32. Zwróć uwagę, że `haar_like_feature` domyślnie ekstrahuje wszystkie możliwe cechy - być może wystarczą tylko niektóre z nich (np. tylko `type-2-x` i `type-2-y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217a3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c44b8496",
   "metadata": {},
   "source": [
    "##### Zadanie 1b \n",
    "\n",
    "Użyj `haar_like_feature_coord` do wyznaczenia koordynat cech Haara dla podanej konfiguracji (rozmiar obrazka, wybrane typy cech). Wartości zwracane przez tę funkcję to para (coords, types) w nieco dziwnym typie:\n",
    "* coords to `np.array` o długości N=liczba cech, zawierający pythonowe listy dwuelementowe, zawierające punkty początkowy i końcowy prostokąta obejmującego daną cechę,\n",
    "* types to `np.array` o długości N=liczba cech, zawierający stringi identyfikujące typ danej cechy.\n",
    "\n",
    "Wybierz jedną dowolną cechę (na chybił trafił) i wyświetl ją używając `draw_haar_like_feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58c938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35ccc36b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zadanie 2 (0.75 pkt | 0.25 pkt)\n",
    "\n",
    "Dokonaj ekstrakcji cech Haara z całego datasetu. Dobierz parametry (skalowanie, typy cech) w taki sposób, by ekstrakcja nie trwała więcej niż 2-5 minut. Uformuj zbiory uczący i walidacyjny na potrzeby uczenia klasyfikatora, pamiętając o losowym samplowaniu z obu klas (np. używając [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)).\n",
    "Wykonaj uczenie klasyfikatora AdaBoost na tym zbiorze, zaczynając od niewielkiej liczby korzeni (N=10), powtarzając 2-3 razy dla większych wartości - ten proces również nie powinien trwać dłużej niż minutę. Na każdym etapie sprawdź, które cechy zostały wybrane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b757f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AdaBoostClassifier(n_estimators=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23a75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe10d9a0",
   "metadata": {},
   "source": [
    "Poszczególne składniki klasyfikatora znajdują się w atrybucie `estimators_` (tworzonym dopiero po sfitowaniu). Aby dobrać się do konkretnych drzew (korzeni) decyzyjnych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_id = 0\n",
    "my_tree = classifier.estimators_[tree_id].tree_ # konkretne drzewo (korzeń) -- NIE ZADZIAŁA PRZED NAUCZENIEM\n",
    "print(my_tree.feature)   # cecha skojarzona z korzeniem; zwróć uwagę, że tylko pierwszy element zawiera id konkretnej cechy\n",
    "print(my_tree.threshold) # próg decyzyjny dla tej cechy\n",
    "print(sklearn.tree.export_text(classifier.estimators_[tree_id])) # pretty-printing powyższego, obiekt musi mieć atrybut 'tree_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f2bbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zadanie 3 (1.0 pkt | 0.25 pkt)\n",
    "\n",
    "Dla wybranego obrazu testowego wykonaj inferencję wykorzystując podejście *sliding-sindow*:\n",
    "* przeskaluj obraz źródłowy (możesz założyć a priori, że wiadomo jakiego rozmiaru będą twarze),\n",
    "* oblicz obraz całkowy,\n",
    "* dla każdego RoI wykonaj ekstrakcję cech Haara...\n",
    "* ...a następnie ich klasyfikację;\n",
    "* jeśli jest pozytywna - zapisz koordynaty danego RoI.\n",
    "\n",
    "Do prezentacji wyników możesz wykorzystać [`cv2.rectangle`](https://docs.opencv.org/4.5.4/d6/d6e/group__imgproc__draw.html#ga07d2f74cadcf8e305e810ce8eed13bc9) (przeskaluj wymiary znalezionego RoI w górę, by narysować bounding-boksa na obrazie oryginalnym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18cd5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "424d2c08",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zadanie 4 (0.75 pkt | 0.0 pkt)\n",
    "\n",
    "Dokonaj optymalizacji algorytmu detekcji cech.\n",
    "\n",
    "##### Zadanie 4a (0.25 pkt)\n",
    "\n",
    "Ze znalezionych korzeni decyzyjnych łatwo wyciągniesz indeksy cech znaczących - wykorzystaj je oraz funkcję `haar_like_feature_coord` do znalezienia podzbioru koordynat cech Haara, które następnie przekażesz do funkcji `haar_like_feature` jako parę opcjonalnych parametrów `feature_type` i `feature_coord`. Sprawdź, o ile szybciej działa teraz ekstraktor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ded24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a97039e4",
   "metadata": {},
   "source": [
    "##### Zadanie 4b (0.5 pkt)\n",
    "\n",
    "Zmodyfikuj swój klasyfikator tak, aby korzystał ze zredukowanego zbioru cech. Proponowane rozwiązania:\n",
    "* (a) zmień parametr `features` w każdym z drzew, tak aby nie szukały cech w oryginalnym wektorze, a w zredukowanym,\n",
    "* (b) nie zmieniaj klasyfikatora, a zamiast tego mapuj zredukowane cechy do wektora o oryginalnej długości.\n",
    "\n",
    "Przetestuj cały pipeline na obrazach testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be84c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c08fa0fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zadanie 5 (0.0 pkt | 1.0 pkt)\n",
    "\n",
    "Wykonaj testy jakości detekcji dla klasyfikatorów o różnej liczbie cech. Wyniki omów, komentując mocne i słabe strony metody - ilościowe miary jakości nie są istotne (m.in. z tego powodu zbiór testowy jest tak niewielki i nie ma etykiet).\n",
    "\n",
    "Wykonaj testy wydajnościowe różnych klasyfikatorów. Dla porównania uwzględnij przynajmniej jeden przed optymalizacją ekstrakcji cech. Wyniki przedstaw w formie tabeli, mierząc średni czas przetwarzania jednego obrazu.\n",
    "\n",
    "#### Zadanie 6 (0.0 pkt | 0.5 pkt)\n",
    "\n",
    "Wykorzystaj dowolny znaleziony w internecie model głębokiej sieci neuronowej do detekcji twarzy, np. [https://github.com/timesler/facenet-pytorch](https://github.com/timesler/facenet-pytorch), porównując jego działanie z uzyskanymi w trakcie laboratorium klasyfikatorami pod względem jakości detekcji i szybkości działania."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
