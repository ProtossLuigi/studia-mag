{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader, stopwords\n",
    "import fasttext\n",
    "from convokit import Corpus, download\n",
    "# from xgboost.sklearn import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import re\n",
    "# from autosklearn.regression import AutoSklearnRegressor\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\proto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_oanc = PlaintextCorpusReader('./OANC-GrAF', '.*\\.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_m1 = fasttext.train_unsupervised('corpus_general_plain.txt', model='cbow')\n",
    "# full_m1.save_model('full_m1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_m2 = fasttext.train_unsupervised('corpus_general_plain.txt', model='skipgram')\n",
    "# full_m2.save_model('full_m2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_m1 = fasttext.train_unsupervised('corpus_specialized_plain.txt', model='cbow')\n",
    "# sample_m1.save_model('sample_m1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_m2 = fasttext.train_unsupervised('corpus_specialized_plain.txt', model='skipgram')\n",
    "# sample_m2.save_model('sample_m2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'\n",
    "threshold = 10\n",
    "# data = Corpus(download('subreddit-communism')).get_utterances_dataframe()[['text', 'meta.score', 'meta.top_level_comment']]\n",
    "# print(data['meta.top_level_comment'])\n",
    "# data = data[~data['meta.top_level_comment'].astype(bool)]\n",
    "# data['target'] = (data['meta.score'] > threshold).astype(int)\n",
    "# data.drop(columns=['meta.score', 'meta.top_level_comment'])\n",
    "# data.to_csv('target_test.csv')\n",
    "data = pd.read_csv('target_test.csv')\n",
    "data['text'] = data['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile('.*\\w.*')\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def clean_tokens(tokens):\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if r.match(token) and token.lower() not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(clean_tokens)\n",
    "data = data.drop(data[data['tokens'].str.len() == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_length(vectors, dst_len=50):\n",
    "    if len(vectors) < dst_len:\n",
    "        return vectors + [[0] * 100] * (dst_len - len(vectors))\n",
    "    elif len(vectors) > dst_len:\n",
    "        return vectors[:dst_len]\n",
    "    else:\n",
    "        return vectors\n",
    "\n",
    "# def get_vectorizer(model):\n",
    "#     def get_text_repr(tokens):\n",
    "#         if tokens:\n",
    "#             vectors = [model.get_word_vector(word) for word in tokens[:50]]\n",
    "#         else:\n",
    "#             vectors = []\n",
    "#         return np.concatenate(equalize_length(vectors))\n",
    "#     return get_text_repr\n",
    "\n",
    "def get_vectorizer(model):\n",
    "    def get_text_repr(tokens):\n",
    "        return torch.tensor(np.stack([model.get_word_vector(word) for word in tokens]))\n",
    "    return get_text_repr\n",
    "\n",
    "# def prepare_data(data, model):\n",
    "#     vectorizer = get_vectorizer(model)\n",
    "#     X = np.stack(data['text'].apply(vectorizer))\n",
    "#     y = np.array(data[target])\n",
    "#     mask = np.random.rand(len(X)) < 0.8\n",
    "#     X_train = X[mask]\n",
    "#     X_test = X[~mask]\n",
    "#     y_train = y[mask]\n",
    "#     y_test = y[~mask]\n",
    "#     return X_train, y_train, X_test, y_test\n",
    "\n",
    "def prepare_data(data, model):\n",
    "    vectorizer = get_vectorizer(model)\n",
    "    X = data['text'].apply(vectorizer)\n",
    "    y = data[target]\n",
    "    mask = np.random.rand(len(X)) < 0.8\n",
    "    X_train = list(X[mask])\n",
    "    X_test = list(X[~mask])\n",
    "    y_train = list(y[mask])\n",
    "    y_test = list(y[~mask])\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_path in ['full_m1.bin', 'full_m2.bin', 'sample_m1.bin', 'sample_m2.bin']:\n",
    "#     vectorizer = fasttext.FastText.load_model(model_path)\n",
    "#     X_train, y_train, X_test, y_test = prepare_data(data, vectorizer)\n",
    "#     regressor = AutoSklearnRegressor(memory_limit=10240)\n",
    "#     regressor.fit(X_train, y_train, X_test, y_test)\n",
    "#     y_pred = regressor.predict(X_test)\n",
    "#     print(model_path)\n",
    "#     print('\\tmse:\\t', mean_squared_error(y_test, y_pred))\n",
    "#     print('\\tr2:\\t', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class score_predictor(nn.Module):\n",
    "\n",
    "#     def __init__(self) -> None:\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Conv1d(100, 100, kernel_size=5),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv1d(100, 100, kernel_size=5),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv1d(100, 100, kernel_size=5),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(8800, 4400),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(4400, 2200),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(2200, 1100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(1100, 1)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y) -> None:\n",
    "        super().__init__()\n",
    "        self.data = list(zip(X, y))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(100, 100, 1, batch_first=True)\n",
    "        self.reg = nn.Linear(100, 2)\n",
    "    \n",
    "    def forward(self, x, x_lengths):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True, enforce_sorted=False)\n",
    "        output, _ = self.rnn(packed)\n",
    "        unpacked, unpacked_len = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        indices = Variable(torch.LongTensor(np.array(unpacked_len) - 1).view(-1, 1)\n",
    "                                                                       .expand(unpacked.size(0), unpacked.size(2))\n",
    "                                                                       .unsqueeze(1)\n",
    "                                                                       .to(device))\n",
    "        last_encoded_states = unpacked.gather(dim=1, index=indices).squeeze(dim=1)\n",
    "        return self.reg(last_encoded_states)\n",
    "\n",
    "\n",
    "def my_collate(batch):\n",
    "    X_batch, y_batch = zip(*batch)\n",
    "    lengths = [sample.shape[0] for sample in X_batch]\n",
    "    X_batch = nn.utils.rnn.pad_sequence(X_batch, batch_first=True)\n",
    "    return X_batch, torch.tensor(y_batch), lengths\n",
    "\n",
    "def to_dl(X, y):\n",
    "    ds = MyDataset(X, y)\n",
    "    dl = DataLoader(ds, 128, shuffle=True, collate_fn=my_collate, pin_memory=True)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dl, loss_fn):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for X_batch, y_batch, lengths in dl:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_true.append(y_batch)\n",
    "        y_pred.append(model(X_batch, lengths).cpu())\n",
    "    y_pred = torch.concat(y_pred)\n",
    "    y_true = torch.concat(y_true)\n",
    "    return f1_score(y_true, torch.argmax(y_pred, axis=1)), loss_fn(y_pred, y_true)\n",
    "\n",
    "def fit(model, loss_fn, optimizer, train_dl, val_dl, epochs=50, show_metrics=True):\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, y_batch, lengths in tqdm(train_dl):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(X_batch, lengths)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if show_metrics:\n",
    "            with torch.no_grad():\n",
    "                train_mse, train_r2 = validate(model, train_dl, loss_fn)\n",
    "                val_mse, val_r2 = validate(model, val_dl, loss_fn)\n",
    "                print(f'Epoch: {epoch}\\ttrain: f1 = {train_mse} loss = {train_r2}\\tval: f1 = {val_mse} loss = {val_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20949\n",
       "1    13328\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " full_m1.bin \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:57<00:00,  3.77it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\ttrain: acc = 0.2544028520499109 loss = 0.6063907146453857\tval: acc = 0.2438884095484613 loss = 0.6059524416923523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:54<00:00,  3.93it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\ttrain: acc = 0.14112639161755075 loss = 0.6078600883483887\tval: acc = 0.13060686015831136 loss = 0.607206404209137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:55<00:00,  3.90it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\ttrain: acc = 0.10588834210079755 loss = 0.6074954271316528\tval: acc = 0.10944935418082938 loss = 0.6060925722122192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:55<00:00,  3.89it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\ttrain: acc = 0.17404410598127876 loss = 0.6058607697486877\tval: acc = 0.15067611075338055 loss = 0.6063243746757507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:56<00:00,  3.83it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\ttrain: acc = 0.22072577628133183 loss = 0.6099084615707397\tval: acc = 0.19672131147540983 loss = 0.6113730669021606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:54<00:00,  3.92it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\ttrain: acc = 0.5874631663541388 loss = 0.6080914735794067\tval: acc = 0.5867490928638625 loss = 0.6091853976249695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.05it/s]\n",
      "  0%|          | 1/215 [00:00<00:28,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\ttrain: acc = 0.25736345438947666 loss = 0.6041103005409241\tval: acc = 0.23230280265819128 loss = 0.607782781124115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:55<00:00,  3.88it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\ttrain: acc = 0.2576349688811695 loss = 0.6021643877029419\tval: acc = 0.2283211678832117 loss = 0.6058568954467773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.06it/s]\n",
      "  0%|          | 1/215 [00:00<00:23,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\ttrain: acc = 0.2880505737648595 loss = 0.6032177209854126\tval: acc = 0.2731034482758621 loss = 0.6080216765403748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  3.99it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\ttrain: acc = 0.1263550135501355 loss = 0.6014016270637512\tval: acc = 0.10910330719399931 loss = 0.6058684587478638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.16it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\ttrain: acc = 0.22593379896750682 loss = 0.6019120812416077\tval: acc = 0.19182293267752845 loss = 0.6086992621421814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.16it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\ttrain: acc = 0.15848561829058427 loss = 0.5999478697776794\tval: acc = 0.128500823723229 loss = 0.6082834005355835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.07it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\ttrain: acc = 0.2546761534511846 loss = 0.6011680364608765\tval: acc = 0.22051433638782145 loss = 0.6097519993782043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.06it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\ttrain: acc = 0.2883221850613155 loss = 0.5983582735061646\tval: acc = 0.26065022421524664 loss = 0.6091066002845764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.16it/s]\n",
      "  1%|          | 2/215 [00:00<00:16, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\ttrain: acc = 0.15001245950660352 loss = 0.5981571674346924\tval: acc = 0.12212212212212212 loss = 0.6093462705612183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.16it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\ttrain: acc = 0.24540702016430171 loss = 0.5985466837882996\tval: acc = 0.20078384082001807 loss = 0.6140167117118835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.10it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\ttrain: acc = 0.11911955114372033 loss = 0.5960961580276489\tval: acc = 0.08510638297872342 loss = 0.6110628247261047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.01it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\ttrain: acc = 0.26473811089195703 loss = 0.5945227146148682\tval: acc = 0.21715976331360945 loss = 0.6113741397857666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.02it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\ttrain: acc = 0.2618679620225215 loss = 0.5945419669151306\tval: acc = 0.2060931899641577 loss = 0.6139510869979858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.14it/s]\n",
      "  1%|          | 2/215 [00:00<00:15, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\ttrain: acc = 0.24988797610156835 loss = 0.5951078534126282\tval: acc = 0.19975859987929995 loss = 0.6157500147819519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:49<00:00,  4.35it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\ttrain: acc = 0.23826166236134327 loss = 0.5937170386314392\tval: acc = 0.18889911070223858 loss = 0.6143258213996887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.20it/s]\n",
      "  0%|          | 1/215 [00:00<00:31,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21\ttrain: acc = 0.2320061255742726 loss = 0.5901762843132019\tval: acc = 0.18092307692307694 loss = 0.6137416958808899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:49<00:00,  4.34it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22\ttrain: acc = 0.246504949746845 loss = 0.590142011642456\tval: acc = 0.19388379204892967 loss = 0.6140758991241455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.11it/s]\n",
      "  0%|          | 1/215 [00:00<00:29,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23\ttrain: acc = 0.2465319662243667 loss = 0.58939528465271\tval: acc = 0.1875574624578609 loss = 0.6189180612564087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.19it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24\ttrain: acc = 0.24956488838441168 loss = 0.5883033871650696\tval: acc = 0.18918918918918917 loss = 0.6176667213439941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.09it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\ttrain: acc = 0.26462313046053604 loss = 0.5879297256469727\tval: acc = 0.20282876918447187 loss = 0.6173470616340637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.10it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26\ttrain: acc = 0.2909116951944425 loss = 0.5860984921455383\tval: acc = 0.23070251517779702 loss = 0.6185218691825867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.04it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27\ttrain: acc = 0.2264740335806326 loss = 0.5868477821350098\tval: acc = 0.1564885496183206 loss = 0.6205868721008301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.13it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28\ttrain: acc = 0.24152509800907063 loss = 0.5851436853408813\tval: acc = 0.17809494260006203 loss = 0.6176840662956238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:54<00:00,  3.97it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29\ttrain: acc = 0.6302839116719243 loss = 0.5869606733322144\tval: acc = 0.6043384498287454 loss = 0.6247021555900574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.14it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30\ttrain: acc = 0.6231679094883004 loss = 0.5899041891098022\tval: acc = 0.595651048407973 loss = 0.6294434666633606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.01it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31\ttrain: acc = 0.24397752636034786 loss = 0.5825608372688293\tval: acc = 0.16791979949874686 loss = 0.6238933801651001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.18it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32\ttrain: acc = 0.27311859878284106 loss = 0.5844873785972595\tval: acc = 0.2028811524609844 loss = 0.6274076700210571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.05it/s]\n",
      "  0%|          | 1/215 [00:00<00:28,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33\ttrain: acc = 0.25842611527683107 loss = 0.5803289413452148\tval: acc = 0.1814254859611231 loss = 0.6259216070175171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.00it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34\ttrain: acc = 0.6280177789147189 loss = 0.5852150321006775\tval: acc = 0.5999742168364058 loss = 0.6324883103370667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.10it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35\ttrain: acc = 0.631914624905279 loss = 0.5834996104240417\tval: acc = 0.604521209042418 loss = 0.6346371173858643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  3.98it/s]\n",
      "  0%|          | 1/215 [00:00<00:26,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36\ttrain: acc = 0.6333502024291499 loss = 0.5819883346557617\tval: acc = 0.602467879404656 loss = 0.6353491544723511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.05it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37\ttrain: acc = 0.2800942979224989 loss = 0.5790876150131226\tval: acc = 0.21212121212121213 loss = 0.630531907081604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.09it/s]\n",
      "  0%|          | 1/215 [00:00<00:35,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38\ttrain: acc = 0.28308958624237524 loss = 0.5796370506286621\tval: acc = 0.20736779560308974 loss = 0.633292019367218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.16it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39\ttrain: acc = 0.27702351806513836 loss = 0.578331708908081\tval: acc = 0.20227408737283065 loss = 0.6318071484565735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.15it/s]\n",
      "  0%|          | 1/215 [00:00<00:32,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40\ttrain: acc = 0.6276524028121088 loss = 0.5827762484550476\tval: acc = 0.596124031007752 loss = 0.6420694589614868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.19it/s]\n",
      "  0%|          | 1/215 [00:00<00:29,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41\ttrain: acc = 0.2566542750929368 loss = 0.593201220035553\tval: acc = 0.2054054054054054 loss = 0.639641284942627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:50<00:00,  4.27it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42\ttrain: acc = 0.2531454833119868 loss = 0.5886709690093994\tval: acc = 0.19065077910174152 loss = 0.6284730434417725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:50<00:00,  4.23it/s]\n",
      "  0%|          | 1/215 [00:00<00:22,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43\ttrain: acc = 0.25806451612903225 loss = 0.5836211442947388\tval: acc = 0.20108695652173914 loss = 0.6270461082458496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.19it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44\ttrain: acc = 0.2879184861717613 loss = 0.5805403590202332\tval: acc = 0.2207868467410452 loss = 0.6291257739067078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.08it/s]\n",
      "  0%|          | 1/215 [00:00<00:26,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45\ttrain: acc = 0.2725228601409084 loss = 0.5787485837936401\tval: acc = 0.19085365853658537 loss = 0.632729172706604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.14it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46\ttrain: acc = 0.26320175770891735 loss = 0.5767174959182739\tval: acc = 0.18600368324125233 loss = 0.6330915093421936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:51<00:00,  4.15it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47\ttrain: acc = 0.28743129351410773 loss = 0.5812234282493591\tval: acc = 0.21523081446633344 loss = 0.640630304813385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:53<00:00,  4.04it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48\ttrain: acc = 0.2806365258774539 loss = 0.5744100213050842\tval: acc = 0.2044977511244378 loss = 0.637283980846405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:52<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49\ttrain: acc = 0.2353207205849099 loss = 0.6094543933868408\tval: acc = 0.19382451849587282 loss = 0.6352572441101074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_44344/895335663.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'full_m1.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'full_m2.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sample_m1.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sample_m2.bin'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFastText\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_dl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtest_dl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_44344/2680096665.py\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(data, model)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_vectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4133\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4134\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4135\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_44344/2680096665.py\u001b[0m in \u001b[0;36mget_text_repr\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_vectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_text_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_word_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_text_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[0mexpanded_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_path in ['full_m1.bin', 'full_m2.bin', 'sample_m1.bin', 'sample_m2.bin']:\n",
    "    vectorizer = fasttext.FastText.load_model(model_path)\n",
    "    X_train, y_train, X_test, y_test = prepare_data(data, vectorizer)\n",
    "    train_dl = to_dl(X_train, y_train)\n",
    "    test_dl = to_dl(X_test, y_test)\n",
    "    model = MyNet().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    print('\\n', model_path, '\\n')\n",
    "    fit(model, loss_fn, optimizer, train_dl, test_dl)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae9258babb9dc6183a521d7a445c874d7696eb0fb582154c3a2ca8b33699b65d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
